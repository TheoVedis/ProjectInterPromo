{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8865c320",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e79371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import lasso_path\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407dbaf",
   "metadata": {},
   "source": [
    "# Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653dbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"C:/Users/Utilisateur/Desktop/Projet_interpromo_2k22/ProjectInterPromo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910d7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier de donnée\n",
    "data_clean2 = pd.read_csv(PROJECT_PATH + \"/data/donnee_v2_ech_train_transfo.csv\")\n",
    "\n",
    "bool_col = []\n",
    "for i in data_clean2.columns:\n",
    "    unique_value = np.unique(data_clean2[i])\n",
    "    \n",
    "    if len(unique_value) == 2:\n",
    "        if 1 in unique_value and 0 in unique_value:\n",
    "            bool_col.append(i)\n",
    "\n",
    "y_col = [\"TOP_FRAUDE\", \"TOP_FRAUDE_CARTE\", \"TOP_FRAUDE_VIREMENT\"]\n",
    "\n",
    "autre_col = list(set(data_clean2.columns) - set(bool_col + y_col + [\"ID\"]))\n",
    "\n",
    "sub_df = data_clean2[autre_col]\n",
    "\n",
    "data_clean2[autre_col] = ((sub_df - sub_df.mean()) / sub_df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65961a97",
   "metadata": {},
   "source": [
    "# Réduction de dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369487c1",
   "metadata": {},
   "source": [
    "## ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6abc575",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.47 GiB for an array with shape (764471, 433) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-50f7e5159a56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pca\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mACP_3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_clean2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TOP_FRAUDE\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPROJECT_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/dev/visualisation/nessrine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-50f7e5159a56>\u001b[0m in \u001b[0;36mACP_3D\u001b[1;34m(df, column_fraude, axes, Data_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mX_pca\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_quanti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_fraude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     df_graph_NF = pd.DataFrame({'X' :X_pca[:,axes[0]][data_quanti[column_fraude]==0] ,\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \"\"\"\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m         \u001b[1;31m# flip eigenvectors' sign to enforce deterministic output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd_flip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\utilisateur\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# perform decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0m\u001b[0;32m    126\u001b[0m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.47 GiB for an array with shape (764471, 433) and data type float64"
     ]
    }
   ],
   "source": [
    "def ACP_3D(df, \n",
    "        column_fraude, \n",
    "        axes,#[num_axe1 , num_axe2]\n",
    "        Data_path\n",
    "       ):\n",
    "    \n",
    "    quali_col = []\n",
    "    for i, name in zip(df.dtypes, df.columns):\n",
    "        if i == \"object\":\n",
    "            quali_col.append(name)\n",
    "\n",
    "    data_quanti = df.drop(columns=quali_col)\n",
    "\n",
    "    pca = PCA()\n",
    "    X_pca=pca.fit_transform(data_quanti.drop(columns=column_fraude))\n",
    "    \n",
    "    df_graph_NF = pd.DataFrame({'X' :X_pca[:,axes[0]][data_quanti[column_fraude]==0] ,\n",
    "                            'Y' :X_pca[:,axes[1]][data_quanti[column_fraude]==0],\n",
    "                            'Z':X_pca[:,axes[2]][data_quanti[column_fraude]==0],\n",
    "                            'F/NF': 'Non Fraude'})\n",
    "    \n",
    "    df_graph_F = pd.DataFrame({'X' :X_pca[:,axes[0]][data_quanti[column_fraude]==1] ,\n",
    "                            'Y' :X_pca[:,axes[1]][data_quanti[column_fraude]==1],\n",
    "                            'Z':X_pca[:,axes[2]][data_quanti[column_fraude]==1],\n",
    "                            'F/NF': 'Fraude'})\n",
    "    \n",
    "    df_graph = pd.concat([df_graph_NF, df_graph_F])\n",
    "    df_graph.to_csv(Data_path+'/G2_ACP_3D.csv', index= False, sep=';')\n",
    "    \n",
    "    return(X_pca[:,axes[0:10]])\n",
    "\n",
    "ACP_3D(data_clean2, \"TOP_FRAUDE\", [0,1,2],PROJECT_PATH+'/dev/visualisation/nessrine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4fdb0",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09309401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA (df, \n",
    "         column_fraude,\n",
    "         alpha, #list(alpha0 , alpha1)\n",
    "         data_path\n",
    "        ):\n",
    "    # enlever les variables qualitatives.\n",
    "    quali_col = []\n",
    "    for i, name in zip(df.dtypes, df.columns):\n",
    "        if i == \"object\":\n",
    "            quali_col.append(name)\n",
    "\n",
    "    data_quanti = df.drop(columns=quali_col)\n",
    "    X , Y = data_quanti.drop(['TOP_FRAUDE', 'TOP_FRAUDE_CARTE', 'TOP_FRAUDE_VIREMENT'],1) , column_fraude\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X , Y)\n",
    "    importances = clf.coef_\n",
    "    importances = importances.reshape(len(X.columns) , 1)\n",
    "\n",
    "    d = dict(zip(data_quanti.columns , importances))\n",
    "    d_tri = sorted(d.items(), key=lambda t: np.abs(t[1]))\n",
    "    \n",
    "    plt.scatter(data_quanti[data_quanti[\"TOP_FRAUDE\"]==0][d_tri[-1][0]], data_quanti[data_quanti[\"TOP_FRAUDE\"]==0][d_tri[-2][0]], alpha=alpha[0], c=\"orange\", label=\"Not Fraude\")\n",
    "    plt.scatter(data_quanti[data_quanti[\"TOP_FRAUDE\"]==1][d_tri[-1][0]], data_quanti[data_quanti[\"TOP_FRAUDE\"]==1][d_tri[-2][0]], alpha=alpha[1], c=\"blue\", label=\"Fraude\")\n",
    "    plt.legend()\n",
    "    plt.title('Fraudes sur les 2 meilleurs axes')\n",
    "    plt.show()\n",
    "    \n",
    "    df_final = df[[d_tri[-1][0],d_tri[-2][0], d_tri[-3][0]]]\n",
    "    df_final['Fraude'] = column_fraude\n",
    "    df_final.columns = ['X', 'Y', 'Z', 'F/NF']\n",
    "    df_final.to_csv(data_path+'/G2_LDA.csv')\n",
    "    return d_tri[-10:]\n",
    "\n",
    "LDA(d, df['TOP_FRAUDE'], [0.1, 0.5], PROJECT_PATH+'/dev/visualisation/nessrine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8248043",
   "metadata": {},
   "source": [
    "## TSNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa141b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_SNE(\n",
    "    df,\n",
    "    column_fraude,\n",
    "    n_composant,  \n",
    "    alphas,\n",
    "    data_path\n",
    "    ):\n",
    "\n",
    "    #preparation des entrées du modèles\n",
    "    X = df.drop(['TOP_FRAUDE', 'TOP_FRAUDE_CARTE', 'TOP_FRAUDE_VIREMENT'],1)\n",
    "    Y = df[str(column_fraude)]\n",
    "    tsne = TSNE(n_components = int(n_composant), verbose=1, random_state=123)\n",
    "    x_tsne = tsne.fit_transform(X) \n",
    "    resultat = pd.DataFrame()\n",
    "    resultat[\"y\"] = Y\n",
    "    resultat[\"comp-1\"] = x_tsne[:,0]\n",
    "    resultat[\"comp-2\"] = x_tsne[:,1]\n",
    "\n",
    "    plt.scatter(resultat[\"comp-1\"][data_quanti[column_fraude]==0], resultat[\"comp-2\"][data_quanti[column_fraude]==0], alpha=alphas[0], c=\"orange\", label=\"Not Fraude\")\n",
    "    plt.scatter(resultat[\"comp-1\"][data_quanti[column_fraude]==1], resultat[\"comp-2\"][data_quanti[column_fraude]==1], alpha=alphas[1], c=\"b\", label=\"Fraude\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    d = {'coordonnées composante 1' : resultat['comp-1'], 'coordonnées composante 2': resultat[\"comp-2\"]}\n",
    "    df_final = pd.DataFrame(d)\n",
    "    df_final.to_csv(data_path + '/G2_T-SNE.csv')\n",
    "    return x_tsne\n",
    "\n",
    "T_SNE(df, 'TOP_FRAUDE',3, [0.1, 0.5], PROJECT_PATH+'/dev/visualisation/nessrine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
